{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d8db476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# Fix noise strength\n",
    "# Fix column index mismatch\n",
    "# apply imputation fix invalid value for discrete values.\n",
    "\n",
    "\n",
    "def generate_distributions_for_discrete_data(data_tensor, discrete_columns, encoder):\n",
    "    probabilities = []\n",
    "    for k, col_index in enumerate(discrete_columns):\n",
    "        x_col = data_tensor[:, col_index]\n",
    "        probabilities.append(torch.softmax(\n",
    "            torch.cat([(((x_col - val) ** 2 + 1e-20) ** -1).reshape(-1, 1) for val in encoder.categories_[k]],\n",
    "                      dim=-1), dim=-1))\n",
    "    probabilities = torch.cat(probabilities, dim=-1)\n",
    "\n",
    "    return probabilities\n",
    "\n",
    "\n",
    "def apply_gumbel_softmax(discrete_logits, feature_sizes, temperature=0.05):\n",
    "    soft_discrete_parts = []\n",
    "    start = 0\n",
    "    for size in feature_sizes:\n",
    "        end = start + size\n",
    "        gumbel_noise = -torch.log(-torch.log(torch.rand_like(discrete_logits[:, start:end]) + 1e-10) + 1e-10)\n",
    "        logits = discrete_logits[:, start:end]\n",
    "        soft = torch.softmax((logits + gumbel_noise) / temperature, dim=-1)\n",
    "        soft_discrete_parts.append(soft)\n",
    "        start = end\n",
    "    discrete_soft = torch.cat(soft_discrete_parts, dim=1)\n",
    "\n",
    "    return discrete_soft\n",
    "\n",
    "\n",
    "def estimate_CMI_soft_kronecker_gaussian(data_tensor, triplet, continuous_columns, discrete_columns, sigma=0.015,\n",
    "                                         temperature=0.6):\n",
    "    \"\"\"\n",
    "    Estimate CMI using:\n",
    "    - Gaussian kernel for continuous features\n",
    "    - Soft Kronecker kernel for discrete features\n",
    "    \"\"\"\n",
    "\n",
    "    def gaussian_kernel(X, Y, sigma):\n",
    "        diff = X[:, None, :] - Y[None, :, :]\n",
    "        return torch.exp(-torch.sum(diff ** 2, dim=2) / (2 * sigma ** 2))\n",
    "\n",
    "    def kronecker_kernel(X, Y, temperature):\n",
    "        diff = torch.abs(X[:, None, :] - Y[None, :, :])\n",
    "        return torch.exp(-torch.sum(diff, dim=2) / temperature)\n",
    "\n",
    "    def kernel_matrix(data, feature_idxs):\n",
    "        sub = data[:, feature_idxs]\n",
    "        cont_idx = [i for i, idx in enumerate(feature_idxs) if idx in continuous_columns]\n",
    "        disc_idx = [i for i, idx in enumerate(feature_idxs) if idx in discrete_columns]\n",
    "\n",
    "        K = None\n",
    "        if cont_idx:\n",
    "            cont_data = sub[:, cont_idx]\n",
    "            K_cont = gaussian_kernel(cont_data, cont_data, sigma)\n",
    "            K = K_cont if K is None else K * K_cont\n",
    "        if disc_idx:\n",
    "            disc_data = sub[:, disc_idx]\n",
    "            K_disc = kronecker_kernel(disc_data, disc_data, temperature)\n",
    "            K = K_disc if K is None else K * K_disc\n",
    "\n",
    "        if K is None:\n",
    "            raise ValueError(\"No valid features provided for kernel computation.\")\n",
    "        return K\n",
    "\n",
    "    def estimate_density(K):\n",
    "        return torch.sum(K, dim=1) / (K.size(0) + 1e-10)\n",
    "\n",
    "    def estimate_entropy(p):\n",
    "        return -torch.mean(torch.log(torch.clamp(p, min=1e-10)))\n",
    "\n",
    "    X, Y, Z = triplet\n",
    "    K_xyz = kernel_matrix(data_tensor, [X, Y, Z])\n",
    "    K_xz = kernel_matrix(data_tensor, [X, Z])\n",
    "    K_yz = kernel_matrix(data_tensor, [Y, Z])\n",
    "    K_z = kernel_matrix(data_tensor, [Z])\n",
    "\n",
    "    return estimate_entropy(estimate_density(K_xz)) + \\\n",
    "        estimate_entropy(estimate_density(K_yz)) - \\\n",
    "        estimate_entropy(estimate_density(K_xyz)) - \\\n",
    "        estimate_entropy(estimate_density(K_z))\n",
    "\n",
    "\n",
    "def estimate_CMI_gumbel_softmax_kernel(data_combined_tensor, triplet, discrete_columns, continuous_columns, encoder,\n",
    "                                       sigma=0.1, temperature=0.05):\n",
    "    \"\"\"\n",
    "    Estimate CMI using Gumbel-softmax for discrete + Gaussian kernel for combined features.\n",
    "    \"\"\"\n",
    "\n",
    "    feature_sizes = [len(cats) for cats in encoder.categories_]\n",
    "    total_discrete = sum(feature_sizes)\n",
    "\n",
    "    discrete_part = data_combined_tensor[:, :total_discrete]\n",
    "    discrete_logits = torch.log(discrete_part + 1e-10)\n",
    "    continuous_part = data_combined_tensor[:, total_discrete:]\n",
    "\n",
    "    discrete_soft = apply_gumbel_softmax(discrete_logits, feature_sizes, temperature=temperature)\n",
    "    data_soft = torch.cat([discrete_soft, continuous_part], dim=1)\n",
    "\n",
    "    col_map = {}\n",
    "    idx = 0\n",
    "    for col, size in zip(discrete_columns, feature_sizes):\n",
    "        col_map[col] = (idx, idx + size)\n",
    "        idx += size\n",
    "    for col in continuous_columns:\n",
    "        col_map[col] = (idx, idx + 1)\n",
    "        idx += 1\n",
    "\n",
    "    def compute_kernel_matrix(data, cols):\n",
    "        slices = [data[:, col_map[c][0]:col_map[c][1]] for c in cols]\n",
    "        selected = torch.cat(slices, dim=1)\n",
    "        dist_sq = torch.cdist(selected, selected, p=2) ** 2\n",
    "        return torch.exp(-dist_sq / (2 * sigma ** 2))\n",
    "\n",
    "    def estimate_density(K):\n",
    "        return K.sum(dim=1) / (K.size(0) + 1e-10)\n",
    "\n",
    "    def estimate_entropy(p):\n",
    "        return -torch.mean(torch.log(torch.clamp(p, min=1e-10)))\n",
    "\n",
    "    X, Y, Z = triplet\n",
    "    K_xyz = compute_kernel_matrix(data_soft, [X, Y, Z])\n",
    "    K_xz = compute_kernel_matrix(data_soft, [X, Z])\n",
    "    K_yz = compute_kernel_matrix(data_soft, [Y, Z])\n",
    "    K_z = compute_kernel_matrix(data_soft, [Z])\n",
    "\n",
    "    return estimate_entropy(estimate_density(K_xz)) + \\\n",
    "        estimate_entropy(estimate_density(K_yz)) - \\\n",
    "        estimate_entropy(estimate_density(K_xyz)) - \\\n",
    "        estimate_entropy(estimate_density(K_z))\n",
    "\n",
    "\n",
    "def estimate_CMI_separate_kernel(data_combined_tensor, triplet,\n",
    "                                 discrete_columns, continuous_columns, encoder,\n",
    "                                 sigma=0.1, temperature=0.05):\n",
    "    \"\"\"\n",
    "    Estimate CMI using separate kernels for discrete (via Gumbel-softmax) and continuous (Gaussian).\n",
    "    \"\"\"\n",
    "\n",
    "    feature_sizes = [len(cats) for cats in encoder.categories_]\n",
    "    total_discrete = sum(feature_sizes)\n",
    "\n",
    "    discrete_part = data_combined_tensor[:, :total_discrete]\n",
    "    discrete_logits = torch.log(discrete_part + 1e-10)\n",
    "    continuous_part = data_combined_tensor[:, total_discrete:]\n",
    "\n",
    "    discrete_soft = apply_gumbel_softmax(discrete_logits, feature_sizes, temperature=temperature)\n",
    "\n",
    "    def gaussian_kernel(X):\n",
    "        dist_sq = torch.cdist(X, X, p=2) ** 2\n",
    "        return torch.exp(-dist_sq / (2 * sigma ** 2))\n",
    "\n",
    "    def estimate_density(K):\n",
    "        return K.sum(dim=1) / (K.size(0) + 1e-10)\n",
    "\n",
    "    def estimate_entropy(p):\n",
    "        return -torch.mean(torch.log(torch.clamp(p, min=1e-10)))\n",
    "\n",
    "    disc_idx_map = {}\n",
    "    cont_idx_map = {}\n",
    "    idx = 0\n",
    "    for col, size in zip(discrete_columns, feature_sizes):\n",
    "        disc_idx_map[col] = (idx, idx + size)\n",
    "        idx += size\n",
    "    for i, col in enumerate(continuous_columns):\n",
    "        cont_idx_map[col] = (i, i + 1)\n",
    "\n",
    "    def compute_kernel(d_cols, c_cols):\n",
    "        n = discrete_soft.size(0)\n",
    "        K_disc = torch.ones((n, n), device=discrete_soft.device)\n",
    "        K_cont = torch.ones((n, n), device=discrete_soft.device)\n",
    "\n",
    "        if d_cols:\n",
    "            d_concat = torch.cat([discrete_soft[:, slice(*disc_idx_map[c])] for c in d_cols], dim=1)\n",
    "            K_disc = gaussian_kernel(d_concat)\n",
    "\n",
    "        if c_cols:\n",
    "            c_concat = torch.cat([continuous_part[:, slice(*cont_idx_map[c])] for c in c_cols], dim=1)\n",
    "            K_cont = gaussian_kernel(c_concat)\n",
    "\n",
    "        return K_disc * K_cont\n",
    "\n",
    "    def split(triplet):\n",
    "        d = [i for i in triplet if i in discrete_columns]\n",
    "        c = [i for i in triplet if i in continuous_columns]\n",
    "        return d, c\n",
    "\n",
    "    X, Y, Z = triplet\n",
    "    d_xyz, c_xyz = split([X, Y, Z])\n",
    "    d_xz, c_xz = split([X, Z])\n",
    "    d_yz, c_yz = split([Y, Z])\n",
    "    d_z, c_z = split([Z])\n",
    "\n",
    "    K_xyz = compute_kernel(d_xyz, c_xyz)\n",
    "    K_xz = compute_kernel(d_xz, c_xz)\n",
    "    K_yz = compute_kernel(d_yz, c_yz)\n",
    "    K_z = compute_kernel(d_z, c_z)\n",
    "\n",
    "    return estimate_entropy(estimate_density(K_xz)) + \\\n",
    "        estimate_entropy(estimate_density(K_yz)) - \\\n",
    "        estimate_entropy(estimate_density(K_xyz)) - \\\n",
    "        estimate_entropy(estimate_density(K_z))\n",
    "\n",
    "\n",
    "def compute_all_cmi_methods(data_tensor, data_combined_tensor,\n",
    "                            triplet, encoder,\n",
    "                            discrete_columns, continuous_columns,\n",
    "                            sigma=0.1, temperature=0.05):\n",
    "    \"\"\"\n",
    "    Compute three CMI values using different kernel estimation strategies, all with torch support.\n",
    "\n",
    "    :param data_tensor: torch.Tensor for mixed kernel method (original data)\n",
    "    :param data_combined_tensor: torch.Tensor for Method 2 (Gumbel + combined features)\n",
    "    :param triplet: tuple of (X, Y, Z) column names\n",
    "    :param encoder: fitted OneHotEncoder\n",
    "    :param discrete_columns: list of discrete column names\n",
    "    :param continuous_columns: list of continuous column names\n",
    "    :param sigma: float, kernel bandwidth\n",
    "    :param temperature: float, Gumbel-softmax temperature\n",
    "    :return: tuple of (cmi1, cmi2, cmi3)\n",
    "    \"\"\"\n",
    "    cmi1 = estimate_CMI_soft_kronecker_gaussian(\n",
    "        data_tensor, triplet, continuous_columns, discrete_columns,\n",
    "        sigma=sigma, temperature=temperature\n",
    "    )\n",
    "\n",
    "    cmi2 = estimate_CMI_gumbel_softmax_kernel(\n",
    "        data_combined_tensor, triplet, discrete_columns, continuous_columns,\n",
    "        encoder=encoder, sigma=sigma, temperature=temperature\n",
    "    )\n",
    "\n",
    "    cmi3 = estimate_CMI_separate_kernel(\n",
    "        data_combined_tensor, triplet,\n",
    "        discrete_columns, continuous_columns, encoder=encoder,\n",
    "        sigma=sigma, temperature=temperature\n",
    "    )\n",
    "\n",
    "    return cmi1, cmi2, cmi3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

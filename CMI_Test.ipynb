{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pot in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.9.4)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pot) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pot) (1.15.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geomloss in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from geomloss) (2.0.2)\n",
      "Requirement already satisfied: torch in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from geomloss) (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->geomloss) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->geomloss) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->geomloss) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->geomloss) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->geomloss) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->geomloss) (75.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->geomloss) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch->geomloss) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch->geomloss) (2.1.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mdatagen in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.1.71)\n",
      "Requirement already satisfied: numpy>=1.25.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mdatagen) (2.0.2)\n",
      "Requirement already satisfied: pandas>=2.0.3 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mdatagen) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>=1.3.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mdatagen) (1.5.2)\n",
      "Requirement already satisfied: missingno>=0.5.2 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mdatagen) (0.5.2)\n",
      "Requirement already satisfied: scipy>=1.11.4 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mdatagen) (1.15.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from missingno>=0.5.2->mdatagen) (3.9.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from missingno>=0.5.2->mdatagen) (0.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\zhossai3\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=2.0.3->mdatagen) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=2.0.3->mdatagen) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=2.0.3->mdatagen) (2024.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=1.3.0->mdatagen) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=1.3.0->mdatagen) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zhossai3\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->mdatagen) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->missingno>=0.5.2->mdatagen) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->missingno>=0.5.2->mdatagen) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->missingno>=0.5.2->mdatagen) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->missingno>=0.5.2->mdatagen) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\zhossai3\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->missingno>=0.5.2->mdatagen) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->missingno>=0.5.2->mdatagen) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->missingno>=0.5.2->mdatagen) (3.1.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pot in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.9.4)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pot) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pot) (1.15.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geomloss in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from geomloss) (2.0.2)\n",
      "Requirement already satisfied: torch in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from geomloss) (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->geomloss) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->geomloss) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->geomloss) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->geomloss) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->geomloss) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->geomloss) (75.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->geomloss) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch->geomloss) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch->geomloss) (2.1.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.15.2)\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [15 lines of output]\n",
      "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "      rather than 'sklearn' for pip commands.\n",
      "      \n",
      "      Here is how to fix this error in the main use cases:\n",
      "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "      - if the 'sklearn' package is used by one of your dependencies,\n",
      "        it would be great if you take some time to track which package uses\n",
      "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "      - as a last resort, set the environment variable\n",
      "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "      \n",
      "      More information is available at\n",
      "      https://github.com/scikit-learn/sklearn-pypi-package\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jax in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: jaxlib<=0.5.0,>=0.5.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jax) (0.5.0)\n",
      "Requirement already satisfied: ml_dtypes>=0.4.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jax) (0.5.1)\n",
      "Requirement already satisfied: numpy>=1.25 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jax) (2.0.2)\n",
      "Requirement already satisfied: opt_einsum in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jax) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.11.1 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jax) (1.15.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chex in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.1.88)\n",
      "Requirement already satisfied: absl-py>=0.9.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chex) (2.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.2.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chex) (4.12.2)\n",
      "Requirement already satisfied: jax>=0.4.27 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chex) (0.5.0)\n",
      "Requirement already satisfied: jaxlib>=0.4.27 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chex) (0.5.0)\n",
      "Requirement already satisfied: numpy>=1.24.1 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chex) (2.0.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chex) (75.3.0)\n",
      "Requirement already satisfied: toolz>=0.9.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chex) (1.0.0)\n",
      "Requirement already satisfied: ml_dtypes>=0.4.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jax>=0.4.27->chex) (0.5.1)\n",
      "Requirement already satisfied: opt_einsum in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jax>=0.4.27->chex) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.11.1 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jax>=0.4.27->chex) (1.15.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: attr in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.3.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optax in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.4)\n",
      "Requirement already satisfied: absl-py>=0.7.1 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optax) (2.1.0)\n",
      "Requirement already satisfied: chex>=0.1.87 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optax) (0.1.88)\n",
      "Requirement already satisfied: jax>=0.4.27 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optax) (0.5.0)\n",
      "Requirement already satisfied: jaxlib>=0.4.27 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optax) (0.5.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optax) (2.0.2)\n",
      "Requirement already satisfied: etils[epy] in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optax) (1.12.0)\n",
      "Requirement already satisfied: typing_extensions>=4.2.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chex>=0.1.87->optax) (4.12.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chex>=0.1.87->optax) (75.3.0)\n",
      "Requirement already satisfied: toolz>=0.9.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chex>=0.1.87->optax) (1.0.0)\n",
      "Requirement already satisfied: ml_dtypes>=0.4.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jax>=0.4.27->optax) (0.5.1)\n",
      "Requirement already satisfied: opt_einsum in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jax>=0.4.27->optax) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.11.1 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jax>=0.4.27->optax) (1.15.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pot\n",
    "!pip install torch\n",
    "!pip install geomloss\n",
    "!pip install wget\n",
    "!pip install mdatagen\n",
    "!pip install pot\n",
    "!pip install torch\n",
    "!pip install geomloss\n",
    "!pip install wget\n",
    "!pip install numpy scipy sklearn\n",
    "!pip install jax\n",
    "!pip install chex\n",
    "!pip install attr\n",
    "!pip install optax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fairlearn in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.24.4 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fairlearn) (2.0.2)\n",
      "Requirement already satisfied: pandas>=2.0.3 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fairlearn) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>=1.2.1 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fairlearn) (1.5.2)\n",
      "Requirement already satisfied: scipy>=1.9.3 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fairlearn) (1.15.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\zhossai3\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=2.0.3->fairlearn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=2.0.3->fairlearn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=2.0.3->fairlearn) (2024.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=1.2.1->fairlearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\zhossai3\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=1.2.1->fairlearn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zhossai3\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install fairlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zhossai3\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\__init__.py:1144: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\tensor\\python_tensor.cpp:434.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "from geomloss import SamplesLoss\n",
    "\n",
    "import ot\n",
    "\n",
    "import os\n",
    "import pickle as pkl\n",
    "import copy\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "\n",
    "from utils import *\n",
    "from SoftImpute import softimpute, cv_softimpute\n",
    "#from DataSetLoader import dataset_loader, ground_truth\n",
    "from SinkhornImputation import SinkhornImputation\n",
    "from Sinkhorn_CMI import SinkhornImputation_CMI\n",
    "from RR_imputer import RRimputer\n",
    "import matplotlib.pyplot as plt\n",
    "from CMI import *\n",
    "from Experiment import *\n",
    "\n",
    "from Inject_Missing_Values import *\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from fairlearn.metrics import (\n",
    "    demographic_parity_difference,  # Measures selection rate disparity\n",
    "    equalized_odds_difference,     # Measures TPR/FPR disparity\n",
    "      # Reports accuracy per group\n",
    ")\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logging.debug(\"test\")\n",
    "import pandas as pd\n",
    "\n",
    "torch.set_default_tensor_type('torch.DoubleTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from mbi import Domain, CliqueVector, Factor, LinearMeasurement\n",
    "#from mbi import marginal_oracles, marginal_loss, synthetic_data\n",
    "from typing import Callable\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import chex\n",
    "import attr\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d =  {\n",
    "    \"A\": [10,10,20,40,70,40,50,80,10,40,20,60,50,30,20],\n",
    "    \"B\": [-5.23122633e-01, -3.83767348e-01,  -5.23122633e-01,  1.91159766e+00,\n",
    " -2.33927097e-01,  1.91159766e+00, -5.23122633e-01, -1.39352679e-01,\n",
    " -1.22976308e-01, -5.23122633e-01, -5.23122633e-01, 1.91159766e+00,\n",
    "  1.91159766e+00, -5.23122633e-01, 1.91159766e+00 ],\n",
    "    \"C\":[15,15,30,60,105,60,75,120,15,60,30,90,75,45,30],\n",
    "    \"D\":[45,30,60,32,58,63,25,55,46,78,92,60,34,27,35]\n",
    "\n",
    "}\n",
    "data = pd.DataFrame(d)\n",
    "data = data.to_numpy()\n",
    "data_torch = torch.tensor(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10.        ,  -0.52312263,  15.        ,  45.        ],\n",
       "       [ 10.        ,  -0.38376735,  15.        ,  30.        ],\n",
       "       [ 20.        ,  -0.52312263,  30.        ,  60.        ],\n",
       "       [ 40.        ,   1.91159766,  60.        ,  32.        ],\n",
       "       [ 70.        ,  -0.2339271 , 105.        ,  58.        ],\n",
       "       [ 40.        ,   1.91159766,  60.        ,  63.        ],\n",
       "       [ 50.        ,  -0.52312263,  75.        ,  25.        ],\n",
       "       [ 80.        ,  -0.13935268, 120.        ,  55.        ],\n",
       "       [ 10.        ,  -0.12297631,  15.        ,  46.        ],\n",
       "       [ 40.        ,  -0.52312263,  60.        ,  78.        ],\n",
       "       [ 20.        ,  -0.52312263,  30.        ,  92.        ],\n",
       "       [ 60.        ,   1.91159766,  90.        ,  60.        ],\n",
       "       [ 50.        ,   1.91159766,  75.        ,  34.        ],\n",
       "       [ 30.        ,  -0.52312263,  45.        ,  27.        ],\n",
       "       [ 20.        ,   1.91159766,  30.        ,  35.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_space = {1:2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = bucketize(data, bucket_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10.   0.  15.  45.]\n",
      " [ 10.   0.  15.  30.]\n",
      " [ 20.   0.  30.  60.]\n",
      " [ 40.   1.  60.  32.]\n",
      " [ 70.   0. 105.  58.]\n",
      " [ 40.   1.  60.  63.]\n",
      " [ 50.   0.  75.  25.]\n",
      " [ 80.   0. 120.  55.]\n",
      " [ 10.   0.  15.  46.]\n",
      " [ 40.   0.  60.  78.]\n",
      " [ 20.   0.  30.  92.]\n",
      " [ 60.   1.  90.  60.]\n",
      " [ 50.   1.  75.  34.]\n",
      " [ 30.   0.  45.  27.]\n",
      " [ 20.   1.  30.  35.]]\n"
     ]
    }
   ],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "h =  {\n",
    "    \"A\": [10,10,35,40,70,40,50,80,10,40,20,60,50,30,20],\n",
    "    \"B\": [1,0,1,0,0,1,0,1,0,0,1,0,1,1,1],\n",
    "    \"C\":[15,12,30,60,105,60,75,120,15,60,30,90,75,45,30],\n",
    "    \"D\":[45,30,60,32,58,63,25,55,46,78,92,60,34,27,35]\n",
    "\n",
    "}\n",
    "h = pd.DataFrame(h)\n",
    "h_numpy = scale(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "p =h_numpy[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputation_accuracy_parity(ground_truth, imputed_data, protected_attr):\n",
    "    \"\"\"\n",
    "    Computes the average absolute difference in imputation MSE for each feature \n",
    "    between two protected groups (0 and 1).\n",
    "\n",
    "    Parameters:\n",
    "        ground_truth (np.ndarray): Original complete dataset (n_samples, n_features)\n",
    "        imputed_data (np.ndarray): Imputed dataset (n_samples, n_features)\n",
    "        protected_attr (np.ndarray): Binary array (n_samples,) representing group membership\n",
    "\n",
    "    Returns:\n",
    "        float: Mean absolute MSE gap across all features\n",
    "    \"\"\"\n",
    "    group0_mask = protected_attr == 0\n",
    "    group1_mask = protected_attr == 1\n",
    "    print( group0_mask)\n",
    "    print( group1_mask)\n",
    "\n",
    "    mae_diffs = []\n",
    "\n",
    "    for i in range(ground_truth.shape[1]):\n",
    "        # Get the ith feature\n",
    "        gt_col = ground_truth[:, i]\n",
    "        print(gt_col)\n",
    "        imp_col = imputed_data[:, i]\n",
    "        print(imp_col)\n",
    "\n",
    "        # MSE for each group\n",
    "        mse_0 = np.mean((gt_col[group0_mask] - imp_col[group0_mask]) )\n",
    "        print(mse_0)\n",
    "        mse_1 = np.mean((gt_col[group1_mask] - imp_col[group1_mask]) )\n",
    "        print(mse_1)\n",
    "\n",
    "        mae_diffs.append(abs(mse_0 - mse_1))\n",
    "\n",
    "    return np.mean(mae_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False False False False\n",
      " False False False]\n",
      "[False False False False False False False False False False False False\n",
      " False False False]\n",
      "[-1.24034735 -1.24034735 -0.77521709  0.15504342  1.55043418  0.15504342\n",
      "  0.62017367  2.01556444 -1.24034735  0.15504342 -0.77521709  1.08530393\n",
      "  0.62017367 -0.31008684 -0.77521709]\n",
      "[-1.24034735 -1.24034735 -0.77521709  0.15504342  1.55043418  0.15504342\n",
      "  0.62017367  2.01556444 -1.24034735  0.15504342 -0.77521709  1.08530393\n",
      "  0.62017367 -0.31008684 -0.77521709]\n",
      "nan\n",
      "nan\n",
      "[ 0.93541435 -1.06904497  0.93541435 -1.06904497 -1.06904497  0.93541435\n",
      " -1.06904497  0.93541435 -1.06904497 -1.06904497  0.93541435 -1.06904497\n",
      "  0.93541435  0.93541435  0.93541435]\n",
      "[ 0.93541435 -1.06904497  0.93541435 -1.06904497 -1.06904497  0.93541435\n",
      " -1.06904497  0.93541435 -1.06904497 -1.06904497  0.93541435 -1.06904497\n",
      "  0.93541435  0.93541435  0.93541435]\n",
      "nan\n",
      "nan\n",
      "[-1.24034735 -1.24034735 -0.77521709  0.15504342  1.55043418  0.15504342\n",
      "  0.62017367  2.01556444 -1.24034735  0.15504342 -0.77521709  1.08530393\n",
      "  0.62017367 -0.31008684 -0.77521709]\n",
      "[-1.24034735 -1.24034735 -0.77521709  0.15504342  1.55043418  0.15504342\n",
      "  0.62017367  2.01556444 -1.24034735  0.15504342 -0.77521709  1.08530393\n",
      "  0.62017367 -0.31008684 -0.77521709]\n",
      "nan\n",
      "nan\n",
      "[-0.22840082 -1.01901904  0.5622174  -0.91360328  0.45680164  0.72034105\n",
      " -1.28255845  0.29867799 -0.17569294  1.51095927  2.2488696   0.5622174\n",
      " -0.80818751 -1.17714268 -0.75547963]\n",
      "[-0.22840082 -1.01901904  0.5622174  -0.91360328  0.45680164  0.72034105\n",
      " -1.28255845  0.29867799 -0.17569294  1.51095927  2.2488696   0.5622174\n",
      " -0.80818751 -1.17714268 -0.75547963]\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zhossai3\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\zhossai3\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\_core\\_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "iapd =imputation_accuracy_parity(data, h_numpy, p)\n",
    "print(iapd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def bucketize_columns(data, bucket_specs):\n",
    "    \"\"\"\n",
    "    Bucketizes specific columns in a dataset using different binning strategies.\n",
    "\n",
    "    :param data: PyTorch tensor (N, D) (continuous values)\n",
    "    :param bucket_specs: Dictionary {column_index: (method, num_bins or bin_edges)}\n",
    "                         Example: {0: ('uniform', 3), 1: ('quantile', 4)}\n",
    "    :return: Discretized tensor\n",
    "    \"\"\"\n",
    "    data_buc = data.detach().clone()  # Ensure no gradients\n",
    "\n",
    "    for col, bins in bucket_specs.items():\n",
    "        feature = data_buc[:, col]  # Extract column\n",
    "        #print(feature)\n",
    "\n",
    "        \n",
    "        min_val, max_val = feature.min(), feature.max()\n",
    "        bin_edges = torch.linspace(min_val, max_val, bins + 1)\n",
    "        print(bin_edges)\n",
    "        bin_edges[-1] += 1e-6 \n",
    "        \n",
    "        # Apply bucketization\n",
    "        data_buc[:, col] = torch.bucketize(feature, bin_edges,right=True) # Start bins from 0\n",
    "        print(data_buc[:,col].long().unique())\n",
    "\n",
    "    return data_buc.long()  # Convert to integer values\n",
    "\n",
    "def compute_probabilities_torch(data, columns):\n",
    "    \"\"\"\n",
    "    Compute probability distributions for given feature columns using PyTorch.\n",
    "\n",
    "    :param data: PyTorch tensor of shape (N, D) (discretized)\n",
    "    :param columns: List of column indices to compute probabilities\n",
    "    :return: Unique values and probability tensor\n",
    "    \"\"\"\n",
    "    unique_vals, counts = torch.unique(data[:, columns], dim=0, return_counts=True)\n",
    "    probs = counts.float() / data.shape[0]\n",
    "    return unique_vals, probs\n",
    "\n",
    "def conditional_mutual_information_torch(data, X_cols, Y_cols, Z_cols, bucket_specs, delta=1):\n",
    "    \"\"\"\n",
    "    Compute Conditional Mutual Information I(X;Y|Z) with bucketization inside.\n",
    "\n",
    "    :param data: PyTorch tensor (N, D) (continuous values)\n",
    "    :param X_cols: List of column indices for X\n",
    "    :param Y_cols: List of column indices for Y\n",
    "    :param Z_cols: List of column indices for Z\n",
    "    :param bucket_specs: Dictionary specifying bucketization for each column\n",
    "    :param delta: Smoothing parameter to avoid log(0)\n",
    "    :return: Conditional Mutual Information (scalar)\n",
    "    \"\"\"\n",
    "    # Apply bucketization inside CMI function\n",
    "    bucketized_data = bucketize_columns(data, bucket_specs)\n",
    "\n",
    "    # Compute probability distributions\n",
    "    unique_Z, P_Z = compute_probabilities_torch(bucketized_data, Z_cols)\n",
    "    unique_XZ, P_XZ = compute_probabilities_torch(bucketized_data, X_cols + Z_cols)\n",
    "    unique_YZ, P_YZ = compute_probabilities_torch(bucketized_data, Y_cols + Z_cols)\n",
    "    unique_XYZ, P_XYZ = compute_probabilities_torch(bucketized_data, X_cols + Y_cols + Z_cols)\n",
    "\n",
    "    cmi = 0\n",
    "    for i in range(len(unique_XYZ)):\n",
    "        xyz = unique_XYZ[i]\n",
    "        z = xyz[len(X_cols + Y_cols):]  # Extract Z values\n",
    "        xz = torch.cat((xyz[:len(X_cols)], z))  # Concatenate X and Z\n",
    "        yz = torch.cat((xyz[len(X_cols):len(X_cols + Y_cols)], z))  # Concatenate Y and Z\n",
    "\n",
    "        mask_z = (unique_Z == z).all(dim=1)\n",
    "        mask_xz = (unique_XZ == xz).all(dim=1)\n",
    "        mask_yz = (unique_YZ == yz).all(dim=1)\n",
    "\n",
    "        if mask_z.any() and mask_xz.any() and mask_yz.any():\n",
    "            P_z = P_Z[mask_z].sum()\n",
    "            P_xyz = P_XYZ[i]\n",
    "            P_xz = P_XZ[mask_xz].sum()\n",
    "            P_yz = P_YZ[mask_yz].sum()\n",
    "\n",
    "            # Compute CMI (avoid log(0) by adding a small constant)\n",
    "            cmi += delta * P_xyz * torch.log2((P_z * P_xyz) / (P_xz * P_yz + 1e-10))\n",
    "\n",
    "    return cmi.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for dimension 0 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 90\u001b[0m\n\u001b[0;32m     87\u001b[0m Z_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m4\u001b[39m]\n\u001b[0;32m     88\u001b[0m bucket_specs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m0\u001b[39m: \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m1\u001b[39m: \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m2\u001b[39m: \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m: \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m4\u001b[39m: \u001b[38;5;241m5\u001b[39m}  \u001b[38;5;66;03m# Bucket specifications\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m cmi_value \u001b[38;5;241m=\u001b[39m \u001b[43mCMI\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconditional_mutual_information\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbucket_specs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCMI:\u001b[39m\u001b[38;5;124m\"\u001b[39m, cmi_value)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Compute gradients\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 64\u001b[0m, in \u001b[0;36mCMI.conditional_mutual_information\u001b[1;34m(data, X_cols, Y_cols, Z_cols, bucket_specs, delta)\u001b[0m\n\u001b[0;32m     62\u001b[0m P_Z \u001b[38;5;241m=\u001b[39m CMI\u001b[38;5;241m.\u001b[39msoft_probability_distribution(bucketized_data, Z_cols)\n\u001b[0;32m     63\u001b[0m P_XZ \u001b[38;5;241m=\u001b[39m CMI\u001b[38;5;241m.\u001b[39msoft_probability_distribution(bucketized_data, X_cols \u001b[38;5;241m+\u001b[39m Z_cols)\n\u001b[1;32m---> 64\u001b[0m P_YZ \u001b[38;5;241m=\u001b[39m \u001b[43mCMI\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoft_probability_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbucketized_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_cols\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mZ_cols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m P_XYZ \u001b[38;5;241m=\u001b[39m CMI\u001b[38;5;241m.\u001b[39msoft_probability_distribution(bucketized_data, X_cols \u001b[38;5;241m+\u001b[39m Y_cols \u001b[38;5;241m+\u001b[39m Z_cols)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Compute differentiable CMI\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 34\u001b[0m, in \u001b[0;36mCMI.soft_probability_distribution\u001b[1;34m(data, columns, num_bins)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msoft_probability_distribution\u001b[39m(data, columns, num_bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m     31\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m    Compute differentiable probability estimates using soft histograms.\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m     feature_subset \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     35\u001b[0m     min_val, max_val \u001b[38;5;241m=\u001b[39m feature_subset\u001b[38;5;241m.\u001b[39mmin(), feature_subset\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m     36\u001b[0m     bin_centers \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinspace(min_val, max_val, num_bins, device\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 5 is out of bounds for dimension 0 with size 5"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class CMI:\n",
    "    @staticmethod\n",
    "    def soft_bucketize(data, bucket_specs):\n",
    "        \"\"\"\n",
    "        Differentiable soft binning using Gaussian kernel estimation.\n",
    "        \"\"\"\n",
    "        data_buc = data.clone()  # Clone to prevent modifying original data\n",
    "\n",
    "        new_data = []\n",
    "        for col, bins in bucket_specs.items():\n",
    "            feature = data_buc[:, col]  # Extract feature column\n",
    "            min_val, max_val = feature.min(), feature.max()\n",
    "            bin_centers = torch.linspace(min_val, max_val, bins, device=data_buc.device).view(-1, 1)\n",
    "\n",
    "            # Compute soft assignments using a Gaussian kernel\n",
    "            distances = torch.abs(feature.unsqueeze(1) - bin_centers.T)\n",
    "            sigma = (max_val - min_val) / bins  # Bandwidth for kernel\n",
    "            soft_assignments = torch.exp(-0.5 * (distances / sigma) ** 2)\n",
    "            soft_assignments = soft_assignments / soft_assignments.sum(dim=1, keepdim=True)\n",
    "\n",
    "            # Compute differentiable bin values\n",
    "            new_feature = (soft_assignments @ bin_centers).squeeze()\n",
    "            new_data.append(new_feature)\n",
    "\n",
    "        return torch.stack(new_data, dim=1)  # Return as new tensor (no in-place ops)\n",
    "\n",
    "    @staticmethod\n",
    "    def soft_probability_distribution(data, columns, num_bins=10):\n",
    "        \"\"\"\n",
    "        Compute differentiable probability estimates using soft histograms.\n",
    "        \"\"\"\n",
    "        feature_subset = data[:, columns]\n",
    "        min_val, max_val = feature_subset.min(), feature_subset.max()\n",
    "        bin_centers = torch.linspace(min_val, max_val, num_bins, device=data.device).view(-1, 1)\n",
    "\n",
    "        # Expand bin_centers to match feature dimensions\n",
    "        bin_centers = bin_centers.expand(num_bins, feature_subset.shape[1])\n",
    "\n",
    "        # Compute Gaussian kernel-based binning\n",
    "        distances = torch.cdist(feature_subset, bin_centers, p=2)\n",
    "        soft_counts = torch.exp(-0.5 * distances**2)\n",
    "        soft_counts = soft_counts / soft_counts.sum(dim=1, keepdim=True)\n",
    "\n",
    "        # Normalize to get probabilities\n",
    "        probs = soft_counts / soft_counts.sum()\n",
    "        return probs\n",
    "\n",
    "    @staticmethod\n",
    "    def conditional_mutual_information(data, X_cols, Y_cols, Z_cols, bucket_specs, delta=1):\n",
    "        \"\"\"\n",
    "        Compute differentiable Conditional Mutual Information I(X;Y|Z).\n",
    "        \"\"\"\n",
    "        if not data.requires_grad:\n",
    "            raise ValueError(\"Input data must have requires_grad=True.\")\n",
    "        \n",
    "        # Soft binning for differentiability (no in-place modification)\n",
    "        bucketized_data = CMI.soft_bucketize(data, bucket_specs)\n",
    "\n",
    "        # Compute differentiable probability distributions\n",
    "        P_Z = CMI.soft_probability_distribution(bucketized_data, Z_cols)\n",
    "        P_XZ = CMI.soft_probability_distribution(bucketized_data, X_cols + Z_cols)\n",
    "        P_YZ = CMI.soft_probability_distribution(bucketized_data, Y_cols + Z_cols)\n",
    "        P_XYZ = CMI.soft_probability_distribution(bucketized_data, X_cols + Y_cols + Z_cols)\n",
    "\n",
    "        # Compute differentiable CMI\n",
    "        cmi = torch.sum(\n",
    "            P_XYZ * (\n",
    "                torch.log2(P_XYZ + 1e-10) \n",
    "                + torch.log2(P_Z + 1e-10)\n",
    "                - torch.log2(P_XZ + 1e-10)\n",
    "                - torch.log2(P_YZ + 1e-10)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return cmi\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "data = torch.randn(100, 7, requires_grad=True)  # Ensure requires_grad=True\n",
    "X_cols = [0, 1]\n",
    "Y_cols = [5]\n",
    "Z_cols = [4]\n",
    "bucket_specs = {0: 5, 1: 5, 2: 5, 3: 5, 4: 5}  # Bucket specifications\n",
    "\n",
    "cmi_value = CMI.conditional_mutual_information(data, X_cols, Y_cols, Z_cols, bucket_specs)\n",
    "print(\"CMI:\", cmi_value)\n",
    "\n",
    "# Compute gradients\n",
    "cmi_value.backward()\n",
    "print(\"Gradients:\", data.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "torch.set_default_tensor_type('torch.DoubleTensor')\n",
    "\n",
    "class CMI:\n",
    "    @staticmethod\n",
    "    def bucketize_columns(data, bucket_specs):\n",
    "        \"\"\"\n",
    "        Efficiently bucketizes columns using vectorized operations.\n",
    "        \"\"\"\n",
    "        data_buc = data.clone()  # Ensure no gradients\n",
    "        \n",
    "        for col, bins in bucket_specs.items():\n",
    "            feature = data_buc[:, col]\n",
    "            min_val, max_val = feature.min(), feature.max()\n",
    "            bin_edges = torch.linspace(min_val, max_val, bins + 1, device=data.device)\n",
    "            bin_edges[-1] += 1e-6  # Ensure max value inclusion\n",
    "            \n",
    "            data_buc[:, col] = torch.searchsorted(bin_edges, feature, right=True) - 1\n",
    "        \n",
    "        return data_buc.long()\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_probabilities_torch(data, columns):\n",
    "        \"\"\"\n",
    "        Compute probability distributions efficiently.\n",
    "        \"\"\"\n",
    "        unique_vals, counts = torch.unique(data[:, columns], dim=0, return_counts=True)\n",
    "        return unique_vals, counts / data.shape[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def conditional_mutual_information(data, X_cols, Y_cols, Z_cols, bucket_specs, delta=1):\n",
    "        \"\"\"\n",
    "        Compute Conditional Mutual Information I(X;Y|Z) efficiently.\n",
    "        \"\"\"\n",
    "        \n",
    "        bucketized_data = CMI.bucketize_columns(data, bucket_specs)\n",
    "            \n",
    "        prob_cache = {}\n",
    "        columns_list = [Z_cols, X_cols + Z_cols, Y_cols + Z_cols, X_cols + Y_cols + Z_cols]\n",
    "        keys = ['Z', 'XZ', 'YZ', 'XYZ']\n",
    "            \n",
    "        for key, cols in zip(keys, columns_list):\n",
    "            prob_cache[key] = CMI.compute_probabilities_torch(bucketized_data, cols)\n",
    "            \n",
    "        unique_XYZ, P_XYZ = prob_cache['XYZ']\n",
    "        unique_Z, P_Z = prob_cache['Z']\n",
    "        unique_XZ, P_XZ = prob_cache['XZ']\n",
    "        unique_YZ, P_YZ = prob_cache['YZ']\n",
    "       \n",
    "            \n",
    "        cmi = torch.zeros(1, device=data.device, dtype=torch.float64)  # No requires_grad=True\n",
    "\n",
    "            \n",
    "        for i, xyz in enumerate(unique_XYZ):\n",
    "                z = xyz[len(X_cols + Y_cols):]\n",
    "                xz = torch.cat((xyz[:len(X_cols)], z))\n",
    "                yz = torch.cat((xyz[len(X_cols):len(X_cols + Y_cols)], z))\n",
    "                \n",
    "                mask_z = (unique_Z == z).all(dim=1)\n",
    "                mask_xz = (unique_XZ == xz).all(dim=1)\n",
    "                mask_yz = (unique_YZ == yz).all(dim=1)\n",
    "                \n",
    "                if mask_z.any() and mask_xz.any() and mask_yz.any():\n",
    "                    P_z = P_Z[mask_z].sum()\n",
    "                    P_xyz = P_XYZ[i]\n",
    "                    P_xz = P_XZ[mask_xz].sum()\n",
    "                    P_yz = P_YZ[mask_yz].sum()\n",
    "                    \n",
    "                    P_z.requires_grad=True\n",
    "                    P_xyz.requires_grad=True\n",
    "                    P_xz.requires_grad=True\n",
    "                    P_yz.requires_grad=True\n",
    "                    cmi_values =  P_xyz * torch.log2((P_z * P_xyz) / (P_xz * P_yz + 1e-10))\n",
    "                    cmi = torch.sum(cmi_values)\n",
    "\n",
    "    \n",
    "    # Ensure non-negative CMI using torch.clamp()\n",
    "        #return torch.clamp(cmi, min=0.0)\n",
    "        return cmi\n",
    "            \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMI: tensor(0.0193, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "data = torch.randn(100, 7, requires_grad=True)  # Ensure requires_grad=True\n",
    "X_cols = [0, 1]\n",
    "Y_cols = [6]\n",
    "Z_cols = [4]\n",
    "bucket_specs = {0: 5, 1: 5, 3: 5, 4: 5}  # Bucket specifications\n",
    "\n",
    "cmi_value = CMI.conditional_mutual_information(data, X_cols, Y_cols, Z_cols, bucket_specs)\n",
    "print(\"CMI:\", cmi_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMI grad_fn: None\n"
     ]
    }
   ],
   "source": [
    "print(\"CMI grad_fn:\", cmi_value.grad_fn)  # Should NOT be None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMI: tensor(nan, grad_fn=<ClampBackward1>)\n",
      "CMI grad_fn: <ClampBackward1 object at 0x00000228F9CB8490>\n",
      "Gradient of prob_XYZ: tensor([0., nan, 0., 0., 0., 0., nan, 0., 0., nan, nan, 0., nan, 0., 0., 0., nan, nan, nan, 0., nan, 0., nan, nan,\n",
      "        0., 0., nan, nan, 0., 0., 0., nan, 0., nan, nan, 0., nan, 0., 0., 0., 0., nan, nan, 0., nan, nan, nan, nan,\n",
      "        0., 0., nan, nan, 0., nan, 0., nan, 0., 0., 0., nan, nan, 0., 0., 0., 0., nan, nan, nan, nan, nan, 0., 0.,\n",
      "        nan, 0., nan, 0., 0., 0., 0., nan, nan, 0., 0., nan, 0., nan, nan, 0., 0., 0., 0., 0., nan, 0., nan, nan,\n",
      "        nan, nan, 0., nan])\n",
      "Gradient of prob_XZ_b: tensor([-0., 0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., -0., 0., 0., -0., -0., 0., -0., 0.,\n",
      "        0., 0., -0., -0., 0., 0., -0., -0., 0., -0., -0., 0., -0., 0., 0., -0., 0., 0., 0., -0., -0., 0., 0., -0.,\n",
      "        0., 0., 0., 0., 0., -0., -0., -0., 0., 0., 0., 0., 0., 0., -0., 0., 0., 0., 0., -0., -0., -0., 0., 0.,\n",
      "        -0., -0., -0., -0., -0., -0., 0., -0., -0., 0., -0., -0., 0., 0., 0., 0., 0., 0., 0., 0., -0., -0., -0., -0.,\n",
      "        -0., -0., 0., 0.])\n",
      "Gradient of prob_YZ_b: tensor([-0., -0., -0., -0., 0., -0., -0., -0., 0., 0., -0., -0., 0., -0., -0., -0., -0., 0., -0., -0., -0., 0., -0., -0.,\n",
      "        -0., -0., -0., 0., -0., -0., -0., -0., 0., 0., -0., 0., 0., -0., -0., -0., 0., -0., 0., 0., -0., 0., -0., -0.,\n",
      "        0., -0., 0., -0., -0., 0., -0., 0., -0., -0., 0., -0., 0., 0., 0., -0., -0., -0., 0., 0., 0., -0., -0., 0.,\n",
      "        -0., 0., -0., 0., 0., 0., -0., -0., -0., 0., 0., -0., -0., -0., -0., 0., 0., 0., -0., 0., 0., 0., -0., 0.,\n",
      "        -0., -0., 0., -0.])\n",
      "Gradient of prob_Z_b: tensor([0., 0., -0., -0., 0., -0., -0., 0., -0., 0., -0., 0., 0., 0., -0., 0., -0., -0., 0., 0., -0., 0., -0., 0.,\n",
      "        -0., -0., -0., 0., -0., -0., 0., -0., 0., 0., -0., 0., 0., -0., -0., 0., 0., 0., -0., -0., -0., -0., 0., -0.,\n",
      "        0., -0., -0., 0., -0., 0., 0., 0., -0., -0., 0., 0., -0., 0., -0., -0., -0., 0., -0., 0., 0., -0., -0., 0.,\n",
      "        -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., -0., -0., 0., 0., 0., 0., 0., -0., 0., 0., -0., -0., 0.,\n",
      "        -0., -0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def calculate_conditional_mutual_information(prob_XYZ, prob_XZ_b, prob_YZ_b, prob_Z_b):\n",
    "    \"\"\"\n",
    "    Calculate Conditional Mutual Information (CMI) using PyTorch.\n",
    "\n",
    "    Returns a differentiable PyTorch tensor.\n",
    "    \"\"\"\n",
    "    # Compute CMI values\n",
    "    cmi_values = prob_XYZ * torch.log2(\n",
    "        (prob_XYZ * prob_Z_b) / (prob_XZ_b * prob_YZ_b + 1e-10)  # Small constant for stability\n",
    "    )\n",
    "    # Sum over all values\n",
    "    cmi = torch.sum(cmi_values)\n",
    "    \n",
    "    # Ensure non-negative CMI using torch.clamp()\n",
    "    return torch.clamp(cmi, min=0.0)\n",
    "\n",
    "# --- Create Sample Differentiable Data ---\n",
    "num_samples = 100\n",
    "prob_XYZ = torch.randn(num_samples, requires_grad=True)  # Continuous, differentiable\n",
    "prob_XZ_b = torch.randn(num_samples, requires_grad=True)\n",
    "prob_YZ_b = torch.randn(num_samples, requires_grad=True)\n",
    "prob_Z_b = torch.randn(num_samples, requires_grad=True)\n",
    "\n",
    "# --- Compute CMI ---\n",
    "cmi_result = calculate_conditional_mutual_information(prob_XYZ, prob_XZ_b, prob_YZ_b, prob_Z_b)\n",
    "\n",
    "# ✅ Check `grad_fn` (it should NOT be None)\n",
    "print(\"CMI:\", cmi_result)\n",
    "print(\"CMI grad_fn:\", cmi_result.grad_fn)  # Should NOT be None (proves differentiability)\n",
    "\n",
    "# ✅ Compute Gradients\n",
    "cmi_result.backward()\n",
    "\n",
    "# ✅ Check if gradients are computed\n",
    "print(\"Gradient of prob_XYZ:\", prob_XYZ.grad)  # Should NOT be None\n",
    "print(\"Gradient of prob_XZ_b:\", prob_XZ_b.grad)  # Should NOT be None\n",
    "print(\"Gradient of prob_YZ_b:\", prob_YZ_b.grad)  # Should NOT be None\n",
    "print(\"Gradient of prob_Z_b:\", prob_Z_b.grad)  # Should NOT be None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def calculate_conditional_mutual_information(prob_XYZ, prob_XZ, prob_YZ, prob_Z):\n",
    "    \"\"\"\n",
    "    Calculate Conditional Mutual Information (CMI) using PyTorch.\n",
    "\n",
    "    Parameters:\n",
    "    - prob_XYZ: Torch tensor for P(X, Y, Z).\n",
    "    - prob_XZ: Torch tensor for P(X, Z).\n",
    "    - prob_YZ: Torch tensor for P(Y, Z).\n",
    "    - prob_Z: Torch tensor for P(Z).\n",
    "\n",
    "    Returns:\n",
    "    - Torch scalar: Conditional mutual information (CMI).\n",
    "    \"\"\"\n",
    "    # Compute CMI using the same formulation as JAX\n",
    "    cmi_values = prob_XYZ * torch.log2(\n",
    "        (prob_XYZ * prob_Z) / (prob_XZ * prob_YZ + 1e-10)  # Small constant for stability\n",
    "    )\n",
    "\n",
    "    # Sum over all values to get the final CMI\n",
    "    cmi = torch.sum(cmi_values)\n",
    "\n",
    "    # Ensure non-negative CMI using torch.clamp()\n",
    "    return torch.clamp(cmi, min=0.0)  # Equivalent to jax.lax.max(cmi, 0)\n",
    "\n",
    "def compute_probabilities_torch(data, columns):\n",
    "    \"\"\"\n",
    "    Compute soft probability distributions using kernel-based estimation.\n",
    "    \"\"\"\n",
    "    feature_subset = data[:, columns]\n",
    "    num_samples = feature_subset.shape[0]\n",
    "\n",
    "    # Estimate probability by applying softmax\n",
    "    probs = torch.softmax(feature_subset, dim=0)\n",
    "\n",
    "    # Normalize to ensure valid probability distribution\n",
    "    return probs / torch.sum(probs)\n",
    "\n",
    "def conditional_mutual_information(data, X_cols, Y_cols, Z_cols):\n",
    "    \"\"\"\n",
    "    Compute differentiable Conditional Mutual Information (CMI) in PyTorch.\n",
    "    \"\"\"\n",
    "    # Compute probability distributions\n",
    "    prob_Z = compute_probabilities_torch(data, Z_cols)\n",
    "    prob_XZ = compute_probabilities_torch(data, X_cols + Z_cols)\n",
    "    prob_YZ = compute_probabilities_torch(data, Y_cols + Z_cols)\n",
    "    prob_XYZ = compute_probabilities_torch(data, X_cols + Y_cols + Z_cols)\n",
    "\n",
    "    # Compute differentiable CMI\n",
    "    cmi = calculate_conditional_mutual_information(prob_XYZ, prob_XZ, prob_YZ, prob_Z)\n",
    "\n",
    "    return cmi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CMI:\n",
    "    @staticmethod\n",
    "    def soft_bucketize(data, bucket_specs):\n",
    "   \n",
    "        bucketized_data = data.clone()  \n",
    "\n",
    "        for col, bins in bucket_specs.items():\n",
    "            feature = bucketized_data[:, col]  # Select column\n",
    "            min_val, max_val = feature.min(), feature.max()\n",
    "            bin_centers = torch.linspace(min_val, max_val, bins, device=data.device)\n",
    "\n",
    "            # Compute soft bin assignments using Gaussian kernel\n",
    "            distances = torch.abs(feature.unsqueeze(1) - bin_centers.unsqueeze(0))\n",
    "            sigma = (max_val - min_val) / bins  # Bandwidth\n",
    "            soft_assignments = torch.exp(-0.5 * (distances / sigma) ** 2)\n",
    "            soft_assignments = soft_assignments / soft_assignments.sum(dim=1, keepdim=True)\n",
    "\n",
    "            # Compute differentiable bin values\n",
    "            new_feature = (soft_assignments @ bin_centers).squeeze()\n",
    "\n",
    "            \n",
    "            bucketized_data = torch.cat([\n",
    "            bucketized_data[:, :col], \n",
    "            new_feature.unsqueeze(1),  \n",
    "            bucketized_data[:, col+1:]\n",
    "        ], dim=1)  \n",
    "\n",
    "        return bucketized_data \n",
    "\n",
    "\n",
    "    \n",
    " \n",
    "    @staticmethod\n",
    "    def compute_probabilities_torch(data, columns, num_bins=10):\n",
    "        \"\"\"\n",
    "        Compute differentiable soft probability distributions.\n",
    "        \"\"\"\n",
    "        feature_subset = data[:, columns]  # Extract relevant columns\n",
    "        print(feature_subset)\n",
    "        min_val, max_val = feature_subset.min(), feature_subset.max()\n",
    "        \n",
    "        \n",
    "        bin_centers = torch.linspace(min_val, max_val, num_bins, device=data.device, dtype=torch.float64).unsqueeze(1).repeat(1, feature_subset.shape[1])\n",
    "\n",
    "\n",
    "       \n",
    "        distances = torch.abs(feature_subset.unsqueeze(1) - bin_centers.unsqueeze(0))\n",
    "        soft_counts = torch.exp(-0.5 * distances**2)  # Gaussian kernel\n",
    "        soft_counts = soft_counts / soft_counts.sum(dim=1, keepdim=True)  # Normalize\n",
    "\n",
    "        # Compute soft probabilities\n",
    "        probs = soft_counts / soft_counts.sum(dim=0, keepdim=True)  \n",
    "\n",
    "\n",
    "        return probs\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    \n",
    "    def conditional_mutual_information(data, X_cols, Y_cols, Z_cols, bucket_specs):\n",
    "        \"\"\"\n",
    "        Compute fully differentiable Conditional Mutual Information (CMI).\n",
    "        \"\"\"\n",
    "        if not data.requires_grad:\n",
    "            raise ValueError(\"Input data must have requires_grad=True.\")\n",
    "\n",
    "       \n",
    "        bucketized_data = CMI.soft_bucketize(data, bucket_specs)\n",
    "\n",
    "        # Compute probability distributions\n",
    "        prob_cache = {}\n",
    "        columns_list = [Z_cols, X_cols + Z_cols, Y_cols + Z_cols, X_cols + Y_cols + Z_cols]\n",
    "        keys = ['Z', 'XZ', 'YZ', 'XYZ']\n",
    "\n",
    "        for key, cols in zip(keys, columns_list):\n",
    "            prob_cache[key] = CMI.compute_probabilities_torch(bucketized_data, cols)\n",
    "\n",
    "        # Retrieve precomputed probabilities\n",
    "        P_Z = prob_cache['Z']\n",
    "        P_XZ = prob_cache['XZ']\n",
    "        P_YZ = prob_cache['YZ']\n",
    "        P_XYZ = prob_cache['XYZ']\n",
    "\n",
    "        cmi_values = P_XYZ * torch.log2(\n",
    "        (P_XYZ * P_Z) / (P_XZ * P_YZ + 1e-10)  # Small constant for stability\n",
    "    )\n",
    "\n",
    "    # Sum over all values to get the final CMI\n",
    "        cmi = torch.sum(cmi_values)\n",
    "       \n",
    "\n",
    "        return cmi  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m bucket_specs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m0\u001b[39m: \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m1\u001b[39m: \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m4\u001b[39m: \u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m5\u001b[39m:\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m: \u001b[38;5;241m5\u001b[39m}  \n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Compute Conditional Mutual Information (CMI)\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m cmi_value \u001b[38;5;241m=\u001b[39m \u001b[43mCMI\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconditional_mutual_information\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbucket_specs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCMI Estimate:\u001b[39m\u001b[38;5;124m\"\u001b[39m, cmi_value)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#print(\"CMI grad_fn:\", cmi_value.grad_fn)  # Should NOT be None\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#print(\"Gradient of data:\", data.grad)  # Should NOT be None\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhossai3\\Desktop\\Fair_Imputation\\CMI.py:178\u001b[0m, in \u001b[0;36mCMI.conditional_mutual_information\u001b[1;34m(data_tensor, bucket_specs, X_cols, Y_cols, Z_cols)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;124;03mApplies bucketization, selects columns, and computes differentiable CMI.\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;124;03m- z_grad: Gradient of CMI w.r.t. Z.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;66;03m# Apply bucketization\u001b[39;00m\n\u001b[1;32m--> 178\u001b[0m bucketized_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mCMI\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbucketize_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbucket_specs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# Select features for X, Y, Z\u001b[39;00m\n\u001b[0;32m    181\u001b[0m X_torch \u001b[38;5;241m=\u001b[39m bucketized_tensor[:, X_cols]\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\zhossai3\\Desktop\\Fair_Imputation\\CMI.py:99\u001b[0m, in \u001b[0;36mCMI.bucketize_tensor\u001b[1;34m(data, bucket_specs)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Bucketizes each column of the PyTorch tensor based on `bucket_specs`.\"\"\"\u001b[39;00m\n\u001b[0;32m     97\u001b[0m bucketized_data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mclone()  \u001b[38;5;66;03m# Clone to avoid modifying the original tensor\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col, bins \u001b[38;5;129;01min\u001b[39;00m \u001b[43mbucket_specs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[0;32m    100\u001b[0m     feature \u001b[38;5;241m=\u001b[39m bucketized_data[:, col]  \u001b[38;5;66;03m# Select column\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;66;03m# Compute quantiles for bin edges\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data\n",
    "data = torch.randn(100, 7, dtype=torch.float64, requires_grad=True)  # Ensure requires_grad=True\n",
    "\n",
    "# Define columns for CMI computation\n",
    "X_cols = [0, 1]  # Predictor variables\n",
    "Y_cols = [6]  # Target variable\n",
    "Z_cols = [5,4]  # Conditional variable\n",
    "\n",
    "# Define bucket specifications (Ensure all columns used are included)\n",
    "bucket_specs = {0: 5, 1: 5, 4: 5,5:5, 6: 5}  \n",
    "# Compute Conditional Mutual Information (CMI)\n",
    "cmi_value = CMI.conditional_mutual_information(data, X_cols, Y_cols, Z_cols, bucket_specs)\n",
    "\n",
    "\n",
    "print(\"CMI Estimate:\", cmi_value)\n",
    "#print(\"CMI grad_fn:\", cmi_value.grad_fn)  # Should NOT be None\n",
    "\n",
    "\n",
    "#cmi_value.backward()\n",
    "\n",
    "\n",
    "#print(\"Gradient of data:\", data.grad)  # Should NOT be None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read CSV file into a Pandas DataFrame\n",
    "groundTruth = pd.read_csv(r'C:\\Users\\zhossai3\\Desktop\\Fair_Imputation\\Data\\Diabetic_Ground_Truth.csv', delimiter=',', header=0)\n",
    "\n",
    "# Store feature columns in a DataFrame\n",
    "\n",
    "\n",
    "X= groundTruth.iloc[:, :-1]  # Selects all rows and all columns except the last one\n",
    "Y = groundTruth.iloc[:, -1]  # Selects all rows and only the last column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundTruth_tensor = torch.tensor(scale(groundTruth)) #converting groundTruth to Tensor, z-score scaling\n",
    "groundTruth_tensor.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_specs = {\n",
    "     \n",
    "    0: 4,   # Column 0 → age (4 bins)\n",
    "    1: 2,  # Column 1 → gender (2 bins)\n",
    "    17: 2,  # Column 17 → label  (2 bins)\n",
    "       # Column 2 → Family Diabetic (2 bins)\n",
    "       # Column 3 → HighBP (2 bins)\n",
    "    4: 4, #column 4 ->  PhysicallyActive (4 bins)\n",
    "    5: 20 #column 5-> BMI (20 bins)\n",
    "    \n",
    "}\n",
    "\n",
    "# Define multiple attributes for X, Y, Z\n",
    "X_cols = [0,1]  # Bucketized sensitive attributes (e.g., sex, race, age)\n",
    "Y_cols = [17]     # Bucketized outcome-related attributes\n",
    "Z_cols = [4,5]  \n",
    "#Z_cols = [2, 5, 6, 10, 13, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMI Estimate: tensor(0.2630)\n",
      "CMI grad_fn: None\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCMI Estimate:\u001b[39m\u001b[38;5;124m\"\u001b[39m, cmi_value)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCMI grad_fn:\u001b[39m\u001b[38;5;124m\"\u001b[39m, cmi_value\u001b[38;5;241m.\u001b[39mgrad_fn)  \u001b[38;5;66;03m# Should NOT be None\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mcmi_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradient of data:\u001b[39m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m.\u001b[39mgrad)  \u001b[38;5;66;03m# Should NOT be None\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhossai3\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zhossai3\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zhossai3\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute Conditional Mutual Information (CMI)\n",
    "cmi_value = CMI.conditional_mutual_information(groundTruth_tensor, X_cols, Y_cols, Z_cols, bucket_specs)\n",
    "\n",
    "\n",
    "print(\"CMI Estimate:\", cmi_value)\n",
    "print(\"CMI grad_fn:\", cmi_value.grad_fn)  # Should NOT be None\n",
    "\n",
    "\n",
    "cmi_value.backward()\n",
    "\n",
    "\n",
    "print(\"Gradient of data:\", data.grad)  # Should NOT be None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucketize_tensor(data, bucket_specs):\n",
    "        \"\"\"Bucketizes each column of the PyTorch tensor based on `bucket_specs`.\"\"\"\n",
    "        bucketized_data = data.clone()  # Clone to avoid modifying the original tensor\n",
    "\n",
    "        for col, bins in bucket_specs.items():\n",
    "            feature = bucketized_data[:, col]  # Select column\n",
    "\n",
    "            # Compute quantiles for bin edges\n",
    "            quantiles = torch.linspace(0, 1, bins + 1, device=data.device)\n",
    "            bin_edges = torch.quantile(feature, quantiles)\n",
    "\n",
    "            # Compute soft bin assignments using Gaussian kernel\n",
    "            bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2  # Use bin centers as reference points\n",
    "            distances = torch.abs(feature.unsqueeze(1) - bin_centers.unsqueeze(0))\n",
    "            sigma = (bin_edges[-1] - bin_edges[0]) / bins  # Bandwidth\n",
    "            soft_assignments = torch.exp(-0.5 * (distances / sigma) ** 2)\n",
    "            soft_assignments = soft_assignments / soft_assignments.sum(dim=1, keepdim=True)\n",
    "\n",
    "            # Compute differentiable bin values\n",
    "            new_feature = (soft_assignments @ bin_centers).squeeze()\n",
    "\n",
    "            # Replace the original column with the bucketized feature\n",
    "            bucketized_data = torch.cat([\n",
    "                bucketized_data[:, :col], \n",
    "                new_feature.unsqueeze(1),  \n",
    "                bucketized_data[:, col+1:]\n",
    "            ], dim=1)  \n",
    "\n",
    "        return bucketized_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bucketize_tensor2(data, bucket_specs):\n",
    "    \"\"\"Bucketizes each column of the PyTorch tensor based on `bucket_specs`.\"\"\"\n",
    "    bucketized_data = data.clone()  \n",
    "\n",
    "    for col, bins in bucket_specs.items():\n",
    "            feature = bucketized_data[:, col]  # Select column\n",
    "            min_val, max_val = feature.min(), feature.max()\n",
    "            bin_centers = torch.linspace(min_val, max_val, bins, device=data.device)\n",
    "\n",
    "            # Compute soft bin assignments using Gaussian kernel\n",
    "            distances = torch.abs(feature.unsqueeze(1) - bin_centers.unsqueeze(0))\n",
    "            sigma = (max_val - min_val) / bins  # Bandwidth\n",
    "            soft_assignments = torch.exp(-0.5 * (distances / sigma) ** 2)\n",
    "            soft_assignments = soft_assignments / soft_assignments.sum(dim=1, keepdim=True)\n",
    "\n",
    "            # Compute differentiable bin values\n",
    "            new_feature = (soft_assignments @ bin_centers).squeeze()\n",
    "\n",
    "            \n",
    "            bucketized_data = torch.cat([\n",
    "            bucketized_data[:, :col], \n",
    "            new_feature.unsqueeze(1),  \n",
    "            bucketized_data[:, col+1:]\n",
    "        ], dim=1)  \n",
    "\n",
    "    return bucketized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0614,  0.3921], grad_fn=<Unique2Backward0>)\n"
     ]
    }
   ],
   "source": [
    "d = bucketize_tensor(groundTruth_tensor,bucket_specs)\n",
    "print(torch.unique(d[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0343,  0.5355], grad_fn=<Unique2Backward0>)\n"
     ]
    }
   ],
   "source": [
    "d = bucketize_tensor2(groundTruth_tensor,bucket_specs)\n",
    "print(torch.unique(d[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read CSV file into a Pandas DataFrame\n",
    "groundTruth = pd.read_csv(r'C:\\Users\\zhossai3\\Desktop\\Fair_Imputation\\Data\\Diabetic_Ground_Truth.csv', delimiter=',', header=0)\n",
    "\n",
    "# Store feature columns in a DataFrame\n",
    "\n",
    "\n",
    "X= groundTruth.iloc[:, :-1]  # Selects all rows and all columns except the last one\n",
    "Y = groundTruth.iloc[:, -1]  # Selects all rows and only the last column\n",
    "groundTruth_tensor = torch.tensor(scale(groundTruth)) #converting groundTruth to Tensor, z-score scaling\n",
    "groundTruth_tensor.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CMI(torch.nn.Module):\n",
    "    def __init__(self, bandwidth=1.0):\n",
    "        super().__init__()\n",
    "        self.bandwidth = bandwidth\n",
    "\n",
    "    def _gaussian_kernel(self, x, y):\n",
    "        \"\"\"\n",
    "        Compute Gaussian kernel density estimate between x and y\n",
    "        x: (n, d)\n",
    "        y: (m, d)\n",
    "        returns: (n,)\n",
    "        \"\"\"\n",
    "        n, d = x.shape\n",
    "        m, _ = y.shape\n",
    "\n",
    "        x = x.unsqueeze(1)  # (n, 1, d)\n",
    "        y = y.unsqueeze(0)  # (1, m, d)\n",
    "\n",
    "        diff = (x - y) / self.bandwidth\n",
    "        exponent = -0.5 * torch.sum(diff ** 2, dim=-1)  # (n, m)\n",
    "        kernel_vals = torch.exp(exponent) / ((2 * torch.pi) ** (d / 2) * self.bandwidth ** d)\n",
    "        return kernel_vals.mean(dim=1)  # (n,)\n",
    "\n",
    "    def estimate_cmi_kde(self, X, Y, Z):\n",
    "        \"\"\"\n",
    "        X, Y, Z are tensors of shape (n_samples, d)\n",
    "        All operations are differentiable\n",
    "        \"\"\"\n",
    "        XYZ = torch.cat([X, Y, Z], dim=1)\n",
    "        XZ = torch.cat([X, Z], dim=1)\n",
    "        YZ = torch.cat([Y, Z], dim=1)\n",
    "\n",
    "        p_xyz = self._gaussian_kernel(XYZ, XYZ)\n",
    "        p_xz = self._gaussian_kernel(XZ, XZ)\n",
    "        p_yz = self._gaussian_kernel(YZ, YZ)\n",
    "        p_z = self._gaussian_kernel(Z, Z)\n",
    "\n",
    "        # Avoid division by zero\n",
    "        eps = 1e-10\n",
    "        p_x_given_z = p_xz / (p_z + eps)\n",
    "        p_y_given_z = p_yz / (p_z + eps)\n",
    "        p_xy_given_z = p_xyz / (p_z + eps)\n",
    "\n",
    "        ratio = p_xy_given_z / (p_x_given_z * p_y_given_z + eps)\n",
    "        log_fraction = torch.log(ratio + eps)\n",
    "\n",
    "        return torch.mean(log_fraction)\n",
    "\n",
    "    def c_m_i(self, data, b, X_cols, Y_cols, Z_cols):\n",
    "        X = data[:, X_cols]\n",
    "        Y = data[:, Y_cols]\n",
    "        Z = data[:, Z_cols]\n",
    "        return self.estimate_cmi_kde(X, Y, Z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CMI:\n",
    "    @staticmethod\n",
    "    def _gaussian_kernel(x, y, bandwidth):\n",
    "        \"\"\"\n",
    "        Compute Gaussian kernel density estimate between x and y\n",
    "        x: (n, d)\n",
    "        y: (m, d)\n",
    "        bandwidth: float\n",
    "        Returns: (n,) tensor of density estimates\n",
    "        \"\"\"\n",
    "        n, d = x.shape\n",
    "        x = x.unsqueeze(1)  # (n, 1, d)\n",
    "        y = y.unsqueeze(0)  # (1, m, d)\n",
    "\n",
    "        diff = (x - y) / bandwidth\n",
    "        exponent = -0.5 * torch.sum(diff ** 2, dim=-1)  # (n, m)\n",
    "        kernel_vals = torch.exp(exponent) / ((2 * torch.pi) ** (d / 2) * bandwidth ** d)\n",
    "        return kernel_vals.mean(dim=1)  # (n,)\n",
    "\n",
    "    @staticmethod\n",
    "    def estimate_cmi_kde(X, Y, Z, bandwidth):\n",
    "        \"\"\"\n",
    "        Estimate Conditional Mutual Information I(X; Y | Z) using KDE\n",
    "        Parameters:\n",
    "            X, Y, Z: torch tensors of shape (n_samples, d)\n",
    "            bandwidth: float\n",
    "        Returns:\n",
    "            CMI estimate (scalar torch tensor)\n",
    "        \"\"\"\n",
    "        XYZ = torch.cat([X, Y, Z], dim=1)\n",
    "        XZ = torch.cat([X, Z], dim=1)\n",
    "        YZ = torch.cat([Y, Z], dim=1)\n",
    "\n",
    "        p_xyz = CMI._gaussian_kernel(XYZ, XYZ, bandwidth)\n",
    "        p_xz  = CMI._gaussian_kernel(XZ, XZ, bandwidth)\n",
    "        p_yz  = CMI._gaussian_kernel(YZ, YZ, bandwidth)\n",
    "        p_z   = CMI._gaussian_kernel(Z, Z, bandwidth)\n",
    "\n",
    "        eps = 1e-10\n",
    "        p_x_given_z = p_xz / (p_z + eps)\n",
    "        p_y_given_z = p_yz / (p_z + eps)\n",
    "        p_xy_given_z = p_xyz / (p_z + eps)\n",
    "\n",
    "        ratio = p_xy_given_z / (p_x_given_z * p_y_given_z + eps)\n",
    "        log_fraction = torch.log(ratio + eps)\n",
    "\n",
    "        return torch.mean(log_fraction)\n",
    "\n",
    "    @staticmethod\n",
    "    def c_m_i(data,b, X_cols, Y_cols, Z_cols, bandwidth=0.3):\n",
    "        \"\"\"\n",
    "        Convenience method to extract columns and estimate CMI.\n",
    "        Parameters:\n",
    "            data: torch tensor (n_samples, n_features)\n",
    "            X_cols, Y_cols, Z_cols: list of int column indices\n",
    "            bandwidth: KDE bandwidth\n",
    "        Returns:\n",
    "            CMI estimate (scalar torch tensor)\n",
    "        \"\"\"\n",
    "        X = data[:, X_cols]\n",
    "        Y = data[:, Y_cols]\n",
    "        Z = data[:, Z_cols]\n",
    "        return CMI.estimate_cmi_kde(X, Y, Z, bandwidth)\n",
    "\n",
    "    @staticmethod\n",
    "    def conditional_mutual_information(data,b, X_cols, Y_cols, Z_cols, bandwidth=0.3):\n",
    "        \"\"\"\n",
    "        Convenience method to extract columns and estimate CMI.\n",
    "        Parameters:\n",
    "            data: torch tensor (n_samples, n_features)\n",
    "            X_cols, Y_cols, Z_cols: list of int column indices\n",
    "            bandwidth: KDE bandwidth\n",
    "        Returns:\n",
    "            CMI estimate (scalar torch tensor)\n",
    "        \"\"\"\n",
    "        X = data[:, X_cols]\n",
    "        Y = data[:, Y_cols]\n",
    "        Z = data[:, Z_cols]\n",
    "        return CMI.estimate_cmi_kde(X, Y, Z, bandwidth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3615, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "bandwidth = 2\n",
    "cmi_value = CMI.c_m_i(groundTruth_tensor, bandwidth, X_cols, Y_cols, Z_cols)\n",
    "print(cmi_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CMI.c_m_i() missing 1 required positional argument: 'Z_cols'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Compute CMI\u001b[39;00m\n\u001b[0;32m      6\u001b[0m cmi_instance \u001b[38;5;241m=\u001b[39m CMI(bandwidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m cmi_value \u001b[38;5;241m=\u001b[39m \u001b[43mcmi_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_m_i\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroundTruth_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ_cols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimated Conditional Mutual Information: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcmi_value\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: CMI.c_m_i() missing 1 required positional argument: 'Z_cols'"
     ]
    }
   ],
   "source": [
    "X_cols = [0, 1]\n",
    "Y_cols = [17]\n",
    "Z_cols = [4, 5]\n",
    "\n",
    "# Compute CMI\n",
    "cmi_instance = CMI(bandwidth=0.2)\n",
    "cmi_value = cmi_instance.c_m_i(groundTruth_tensor, X_cols, Y_cols, Z_cols)\n",
    "\n",
    "print(f\"Estimated Conditional Mutual Information: {cmi_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0573, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "bandwidth = 2\n",
    "cmi_value = CMI.c_m_i(groundTruth_tensor, bandwidth, X_cols, Y_cols, Z_cols)\n",
    "print(cmi_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
